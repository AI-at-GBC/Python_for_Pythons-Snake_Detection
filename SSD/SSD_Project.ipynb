{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oeyP0aYes9Zs",
    "outputId": "e7258196-92b9-4fd6-a350-535eb35a00c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DEGpXLl3tQVX"
   },
   "source": [
    "## **Cloning TFOD 2.0 Github**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kFkdXoEltLY9",
    "outputId": "6699e6a4-9ae4-4afe-8170-4a749eaa95b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'models'...\n",
      "remote: Enumerating objects: 56138, done.\u001b[K\n",
      "remote: Counting objects: 100% (182/182), done.\u001b[K\n",
      "remote: Compressing objects: 100% (127/127), done.\u001b[K\n",
      "remote: Total 56138 (delta 79), reused 142 (delta 55), pack-reused 55956\u001b[K\n",
      "Receiving objects: 100% (56138/56138), 572.16 MiB | 26.98 MiB/s, done.\n",
      "Resolving deltas: 100% (38684/38684), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/tensorflow/models.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "aJ4YzpQ4tMlz",
    "outputId": "83d9d6ac-6cca-4245-80d6-9ceb40057a38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Mike\\\\Downloads'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ZwI0sTdtMsc",
    "outputId": "aa8ac80e-c7c4-445c-f14c-b57045c6ca36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mike\\Documents\\TensorFlow\\models\\research\n"
     ]
    }
   ],
   "source": [
    "cd C:/Users/Mike/Documents/TensorFlow/models/research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0XRlMiuEtM4R",
    "outputId": "b2cb5be0-255e-46ad-b7e6-88723a95ead7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mike\\Documents\\TensorFlow\\models\\research\\cocoapi\\PythonAPI\n"
     ]
    }
   ],
   "source": [
    "cd cocoapi/PythonAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rLq79dR0uQFt"
   },
   "source": [
    "### Installing the Object Detection API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MZouxA5TuWgV",
    "outputId": "b23dd796-0bf8-4c52-e986-b09984f527e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mike\\Documents\\TensorFlow\\models\\research\n"
     ]
    }
   ],
   "source": [
    "cd C:/Users/Mike/Documents/TensorFlow/models/research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q635Jl58uWjI"
   },
   "outputs": [],
   "source": [
    "cp object_detection/packages/tf2/setup.py ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZyrPaXSxuWmI",
    "outputId": "73a77be0-e08f-47b5-e67a-dc9b773d2f5a",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /content/models/research\n",
      "Requirement already satisfied: avro-python3 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.10.2)\n",
      "Requirement already satisfied: apache-beam in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.28.0)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
      "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.22)\n",
      "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
      "Requirement already satisfied: tf-slim in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
      "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.2)\n",
      "Requirement already satisfied: lvis in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.3)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.5)\n",
      "Requirement already satisfied: tf-models-official in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.4.0)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
      "Requirement already satisfied: fastavro<2,>=0.21.4 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.4.0)\n",
      "Requirement already satisfied: grpcio<2,>=1.29.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.32.0)\n",
      "Requirement already satisfied: httplib2<0.18.0,>=0.8 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (0.17.4)\n",
      "Requirement already satisfied: future<1.0.0,>=0.18.2 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (0.18.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (2.25.1)\n",
      "Requirement already satisfied: numpy<1.20.0,>=1.14.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions<3.8.0,>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.7.4.3)\n",
      "Requirement already satisfied: pyarrow<3.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (2.0.0)\n",
      "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.11.3)\n",
      "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (0.3.1.1)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (2.8.1)\n",
      "Requirement already satisfied: mock<3.0.0,>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (2.0.0)\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
      "Requirement already satisfied: protobuf<4,>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.12.4)\n",
      "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (2018.9)\n",
      "Requirement already satisfied: oauth2client<5,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (4.1.3)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (2.6.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (1.3.1)\n",
      "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf-slim->object-detection==0.1) (0.12.0)\n",
      "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools->object-detection==0.1) (54.2.0)\n",
      "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n",
      "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.5.12)\n",
      "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (8.0.0)\n",
      "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (0.5.0)\n",
      "Requirement already satisfied: tensorflow>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (2.4.1)\n",
      "Requirement already satisfied: seqeval in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.2.2)\n",
      "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (0.4.0)\n",
      "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (4.5.1.48)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (5.4.1)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (0.6)\n",
      "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (5.4.8)\n",
      "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (4.0.1)\n",
      "Requirement already satisfied: google-cloud-bigquery>=0.31.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.21.0)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (0.1.95)\n",
      "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (0.12.0)\n",
      "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.12.8)\n",
      "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (0.12.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.0.4)\n",
      "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.7/dist-packages (from mock<3.0.0,>=1.0.1->apache-beam->object-detection==0.1) (5.5.1)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (4.7.2)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.2.8)\n",
      "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (4.41.1)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (4.0.1)\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official->object-detection==0.1) (0.1.6)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (2.10.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (0.3.3)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.12)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (2.4.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.6.3)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.12.1)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (2.4.1)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (0.2.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (0.36.2)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (3.3.0)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official->object-detection==0.1) (0.22.2.post1)\n",
      "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (2.3)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (20.3.0)\n",
      "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (0.29.0)\n",
      "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (5.1.2)\n",
      "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.0.3)\n",
      "Requirement already satisfied: google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (0.4.1)\n",
      "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.26.3)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (0.0.4)\n",
      "Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.28.1)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (3.0.1)\n",
      "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official->object-detection==0.1) (2.7.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official->object-detection==0.1) (1.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.8.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (0.4.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (3.3.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official->object-detection==0.1) (1.0.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow-datasets->tf-models-official->object-detection==0.1) (1.53.0)\n",
      "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->tf-models-official->object-detection==0.1) (3.4.1)\n",
      "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (20.9)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (4.2.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (3.10.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.4.0->tf-models-official->object-detection==0.1) (3.1.0)\n",
      "Building wheels for collected packages: object-detection\n",
      "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for object-detection: filename=object_detection-0.1-cp37-none-any.whl size=1643821 sha256=ab872278ccc4842f0f258d8ef86696064cb7b7843379ccac32fdbd86cb5c45f1\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-tur02ldf/wheels/94/49/4b/39b051683087a22ef7e80ec52152a27249d1a644ccf4e442ea\n",
      "Successfully built object-detection\n",
      "Installing collected packages: object-detection\n",
      "  Found existing installation: object-detection 0.1\n",
      "    Uninstalling object-detection-0.1:\n",
      "      Successfully uninstalled object-detection-0.1\n",
      "Successfully installed object-detection-0.1\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cjlR4lsmuWpE",
    "outputId": "f75abc7a-1454-43ec-d04f-503192ccd296",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tests under Python 3.9.12: C:\\Users\\Mike\\.conda\\envs\\snakes_breed\\python.exe\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "C:\\Users\\Mike\\.conda\\envs\\snakes_breed\\lib\\site-packages\\object_detection\\builders\\model_builder.py:1100: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead\n",
      "  logging.warn(('Building experimental DeepMAC meta-arch.'\n",
      "W0408 07:53:22.579028  8228 model_builder.py:1100] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.02s\n",
      "I0408 07:53:22.748028  8228 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.8s\n",
      "I0408 07:53:23.548818  8228 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.8s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.18s\n",
      "I0408 07:53:23.727885  8228 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.18s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.17s\n",
      "I0408 07:53:23.896027  8228 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.17s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.17s\n",
      "I0408 07:53:25.065065  8228 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.17s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "I0408 07:53:25.066067  8228 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
      "I0408 07:53:25.082068  8228 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
      "I0408 07:53:25.091065  8228 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
      "I0408 07:53:25.101065  8228 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.07s\n",
      "I0408 07:53:25.167071  8228 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.07s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.06s\n",
      "I0408 07:53:25.229070  8228 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.06s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.06s\n",
      "I0408 07:53:25.294037  8228 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.06s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.06s\n",
      "I0408 07:53:25.358087  8228 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.06s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.06s\n",
      "I0408 07:53:25.420054  8228 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.06s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.02s\n",
      "I0408 07:53:25.438090  8228 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "I0408 07:53:25.551093  8228 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
      "I0408 07:53:25.551093  8228 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n",
      "I0408 07:53:25.551093  8228 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 3\n",
      "I0408 07:53:25.552093  8228 efficientnet_model.py:144] round_filter input=32 output=32\n",
      "I0408 07:53:25.563093  8228 efficientnet_model.py:144] round_filter input=32 output=32\n",
      "I0408 07:53:25.563093  8228 efficientnet_model.py:144] round_filter input=16 output=16\n",
      "I0408 07:53:25.600516  8228 efficientnet_model.py:144] round_filter input=16 output=16\n",
      "I0408 07:53:25.600516  8228 efficientnet_model.py:144] round_filter input=24 output=24\n",
      "I0408 07:53:25.695486  8228 efficientnet_model.py:144] round_filter input=24 output=24\n",
      "I0408 07:53:25.696486  8228 efficientnet_model.py:144] round_filter input=40 output=40\n",
      "I0408 07:53:25.791515  8228 efficientnet_model.py:144] round_filter input=40 output=40\n",
      "I0408 07:53:25.791515  8228 efficientnet_model.py:144] round_filter input=80 output=80\n",
      "I0408 07:53:26.028798  8228 efficientnet_model.py:144] round_filter input=80 output=80\n",
      "I0408 07:53:26.029828  8228 efficientnet_model.py:144] round_filter input=112 output=112\n",
      "I0408 07:53:26.173797  8228 efficientnet_model.py:144] round_filter input=112 output=112\n",
      "I0408 07:53:26.173797  8228 efficientnet_model.py:144] round_filter input=192 output=192\n",
      "I0408 07:53:26.378798  8228 efficientnet_model.py:144] round_filter input=192 output=192\n",
      "I0408 07:53:26.378798  8228 efficientnet_model.py:144] round_filter input=320 output=320\n",
      "I0408 07:53:26.429842  8228 efficientnet_model.py:144] round_filter input=1280 output=1280\n",
      "I0408 07:53:26.450827  8228 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0408 07:53:26.488797  8228 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
      "I0408 07:53:26.488797  8228 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\n",
      "I0408 07:53:26.488797  8228 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 4\n",
      "I0408 07:53:26.489827  8228 efficientnet_model.py:144] round_filter input=32 output=32\n",
      "I0408 07:53:26.500826  8228 efficientnet_model.py:144] round_filter input=32 output=32\n",
      "I0408 07:53:26.500826  8228 efficientnet_model.py:144] round_filter input=16 output=16\n",
      "I0408 07:53:26.584831  8228 efficientnet_model.py:144] round_filter input=16 output=16\n",
      "I0408 07:53:26.584831  8228 efficientnet_model.py:144] round_filter input=24 output=24\n",
      "I0408 07:53:26.742830  8228 efficientnet_model.py:144] round_filter input=24 output=24\n",
      "I0408 07:53:26.742830  8228 efficientnet_model.py:144] round_filter input=40 output=40\n",
      "I0408 07:53:26.898797  8228 efficientnet_model.py:144] round_filter input=40 output=40\n",
      "I0408 07:53:26.898797  8228 efficientnet_model.py:144] round_filter input=80 output=80\n",
      "I0408 07:53:27.094826  8228 efficientnet_model.py:144] round_filter input=80 output=80\n",
      "I0408 07:53:27.094826  8228 efficientnet_model.py:144] round_filter input=112 output=112\n",
      "I0408 07:53:27.291825  8228 efficientnet_model.py:144] round_filter input=112 output=112\n",
      "I0408 07:53:27.291825  8228 efficientnet_model.py:144] round_filter input=192 output=192\n",
      "I0408 07:53:27.537798  8228 efficientnet_model.py:144] round_filter input=192 output=192\n",
      "I0408 07:53:27.537798  8228 efficientnet_model.py:144] round_filter input=320 output=320\n",
      "I0408 07:53:27.633826  8228 efficientnet_model.py:144] round_filter input=1280 output=1280\n",
      "I0408 07:53:27.651828  8228 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0408 07:53:27.692826  8228 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
      "I0408 07:53:27.692826  8228 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 112\n",
      "I0408 07:53:27.692826  8228 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 5\n",
      "I0408 07:53:27.694827  8228 efficientnet_model.py:144] round_filter input=32 output=32\n",
      "I0408 07:53:27.703826  8228 efficientnet_model.py:144] round_filter input=32 output=32\n",
      "I0408 07:53:27.703826  8228 efficientnet_model.py:144] round_filter input=16 output=16\n",
      "I0408 07:53:27.779798  8228 efficientnet_model.py:144] round_filter input=16 output=16\n",
      "I0408 07:53:27.780827  8228 efficientnet_model.py:144] round_filter input=24 output=24\n",
      "I0408 07:53:27.924829  8228 efficientnet_model.py:144] round_filter input=24 output=24\n",
      "I0408 07:53:27.924829  8228 efficientnet_model.py:144] round_filter input=40 output=48\n",
      "I0408 07:53:28.077826  8228 efficientnet_model.py:144] round_filter input=40 output=48\n",
      "I0408 07:53:28.077826  8228 efficientnet_model.py:144] round_filter input=80 output=88\n",
      "I0408 07:53:28.283826  8228 efficientnet_model.py:144] round_filter input=80 output=88\n",
      "I0408 07:53:28.283826  8228 efficientnet_model.py:144] round_filter input=112 output=120\n",
      "I0408 07:53:28.581055  8228 efficientnet_model.py:144] round_filter input=112 output=120\n",
      "I0408 07:53:28.581055  8228 efficientnet_model.py:144] round_filter input=192 output=208\n",
      "I0408 07:53:28.821052  8228 efficientnet_model.py:144] round_filter input=192 output=208\n",
      "I0408 07:53:28.821052  8228 efficientnet_model.py:144] round_filter input=320 output=352\n",
      "I0408 07:53:28.916023  8228 efficientnet_model.py:144] round_filter input=1280 output=1408\n",
      "I0408 07:53:28.934054  8228 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0408 07:53:28.976053  8228 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
      "I0408 07:53:28.976053  8228 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n",
      "I0408 07:53:28.976053  8228 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 6\n",
      "I0408 07:53:28.977055  8228 efficientnet_model.py:144] round_filter input=32 output=40\n",
      "I0408 07:53:28.987052  8228 efficientnet_model.py:144] round_filter input=32 output=40\n",
      "I0408 07:53:28.987052  8228 efficientnet_model.py:144] round_filter input=16 output=24\n",
      "I0408 07:53:29.063051  8228 efficientnet_model.py:144] round_filter input=16 output=24\n",
      "I0408 07:53:29.063051  8228 efficientnet_model.py:144] round_filter input=24 output=32\n",
      "I0408 07:53:29.209052  8228 efficientnet_model.py:144] round_filter input=24 output=32\n",
      "I0408 07:53:29.209052  8228 efficientnet_model.py:144] round_filter input=40 output=48\n",
      "I0408 07:53:29.355053  8228 efficientnet_model.py:144] round_filter input=40 output=48\n",
      "I0408 07:53:29.355053  8228 efficientnet_model.py:144] round_filter input=80 output=96\n",
      "I0408 07:53:29.596052  8228 efficientnet_model.py:144] round_filter input=80 output=96\n",
      "I0408 07:53:29.596052  8228 efficientnet_model.py:144] round_filter input=112 output=136\n",
      "I0408 07:53:29.837052  8228 efficientnet_model.py:144] round_filter input=112 output=136\n",
      "I0408 07:53:29.837052  8228 efficientnet_model.py:144] round_filter input=192 output=232\n",
      "I0408 07:53:30.130052  8228 efficientnet_model.py:144] round_filter input=192 output=232\n",
      "I0408 07:53:30.131055  8228 efficientnet_model.py:144] round_filter input=320 output=384\n",
      "I0408 07:53:30.227023  8228 efficientnet_model.py:144] round_filter input=1280 output=1536\n",
      "I0408 07:53:30.246067  8228 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0408 07:53:30.291052  8228 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
      "I0408 07:53:30.291052  8228 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\n",
      "I0408 07:53:30.291052  8228 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 7\n",
      "I0408 07:53:30.292053  8228 efficientnet_model.py:144] round_filter input=32 output=48\n",
      "I0408 07:53:30.303052  8228 efficientnet_model.py:144] round_filter input=32 output=48\n",
      "I0408 07:53:30.303052  8228 efficientnet_model.py:144] round_filter input=16 output=24\n",
      "I0408 07:53:30.377052  8228 efficientnet_model.py:144] round_filter input=16 output=24\n",
      "I0408 07:53:30.377052  8228 efficientnet_model.py:144] round_filter input=24 output=32\n",
      "I0408 07:53:30.569052  8228 efficientnet_model.py:144] round_filter input=24 output=32\n",
      "I0408 07:53:30.569052  8228 efficientnet_model.py:144] round_filter input=40 output=56\n",
      "I0408 07:53:30.765055  8228 efficientnet_model.py:144] round_filter input=40 output=56\n",
      "I0408 07:53:30.765055  8228 efficientnet_model.py:144] round_filter input=80 output=112\n",
      "I0408 07:53:31.055052  8228 efficientnet_model.py:144] round_filter input=80 output=112\n",
      "I0408 07:53:31.055052  8228 efficientnet_model.py:144] round_filter input=112 output=160\n",
      "I0408 07:53:31.349022  8228 efficientnet_model.py:144] round_filter input=112 output=160\n",
      "I0408 07:53:31.349022  8228 efficientnet_model.py:144] round_filter input=192 output=272\n",
      "I0408 07:53:31.882153  8228 efficientnet_model.py:144] round_filter input=192 output=272\n",
      "I0408 07:53:31.882153  8228 efficientnet_model.py:144] round_filter input=320 output=448\n",
      "I0408 07:53:31.978185  8228 efficientnet_model.py:144] round_filter input=1280 output=1792\n",
      "I0408 07:53:31.999153  8228 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0408 07:53:32.054183  8228 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
      "I0408 07:53:32.054183  8228 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 288\n",
      "I0408 07:53:32.054183  8228 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 7\n",
      "I0408 07:53:32.055185  8228 efficientnet_model.py:144] round_filter input=32 output=48\n",
      "I0408 07:53:32.065184  8228 efficientnet_model.py:144] round_filter input=32 output=48\n",
      "I0408 07:53:32.065184  8228 efficientnet_model.py:144] round_filter input=16 output=24\n",
      "I0408 07:53:32.182183  8228 efficientnet_model.py:144] round_filter input=16 output=24\n",
      "I0408 07:53:32.182183  8228 efficientnet_model.py:144] round_filter input=24 output=40\n",
      "I0408 07:53:32.425183  8228 efficientnet_model.py:144] round_filter input=24 output=40\n",
      "I0408 07:53:32.426183  8228 efficientnet_model.py:144] round_filter input=40 output=64\n",
      "I0408 07:53:32.669183  8228 efficientnet_model.py:144] round_filter input=40 output=64\n",
      "I0408 07:53:32.669183  8228 efficientnet_model.py:144] round_filter input=80 output=128\n",
      "I0408 07:53:33.010182  8228 efficientnet_model.py:144] round_filter input=80 output=128\n",
      "I0408 07:53:33.010182  8228 efficientnet_model.py:144] round_filter input=112 output=176\n",
      "I0408 07:53:33.355185  8228 efficientnet_model.py:144] round_filter input=112 output=176\n",
      "I0408 07:53:33.355185  8228 efficientnet_model.py:144] round_filter input=192 output=304\n",
      "I0408 07:53:33.793183  8228 efficientnet_model.py:144] round_filter input=192 output=304\n",
      "I0408 07:53:33.793183  8228 efficientnet_model.py:144] round_filter input=320 output=512\n",
      "I0408 07:53:33.941153  8228 efficientnet_model.py:144] round_filter input=1280 output=2048\n",
      "I0408 07:53:33.969186  8228 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0408 07:53:34.032186  8228 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
      "I0408 07:53:34.032186  8228 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
      "I0408 07:53:34.032186  8228 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 8\n",
      "I0408 07:53:34.033186  8228 efficientnet_model.py:144] round_filter input=32 output=56\n",
      "I0408 07:53:34.043183  8228 efficientnet_model.py:144] round_filter input=32 output=56\n",
      "I0408 07:53:34.043183  8228 efficientnet_model.py:144] round_filter input=16 output=32\n",
      "I0408 07:53:34.162212  8228 efficientnet_model.py:144] round_filter input=16 output=32\n",
      "I0408 07:53:34.162212  8228 efficientnet_model.py:144] round_filter input=24 output=40\n",
      "I0408 07:53:34.452213  8228 efficientnet_model.py:144] round_filter input=24 output=40\n",
      "I0408 07:53:34.452213  8228 efficientnet_model.py:144] round_filter input=40 output=72\n",
      "I0408 07:53:34.904212  8228 efficientnet_model.py:144] round_filter input=40 output=72\n",
      "I0408 07:53:34.904212  8228 efficientnet_model.py:144] round_filter input=80 output=144\n",
      "I0408 07:53:35.295212  8228 efficientnet_model.py:144] round_filter input=80 output=144\n",
      "I0408 07:53:35.295212  8228 efficientnet_model.py:144] round_filter input=112 output=200\n",
      "I0408 07:53:35.691213  8228 efficientnet_model.py:144] round_filter input=112 output=200\n",
      "I0408 07:53:35.691213  8228 efficientnet_model.py:144] round_filter input=192 output=344\n",
      "I0408 07:53:36.230183  8228 efficientnet_model.py:144] round_filter input=192 output=344\n",
      "I0408 07:53:36.230183  8228 efficientnet_model.py:144] round_filter input=320 output=576\n",
      "I0408 07:53:36.374213  8228 efficientnet_model.py:144] round_filter input=1280 output=2304\n",
      "I0408 07:53:36.392212  8228 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0408 07:53:36.462213  8228 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
      "I0408 07:53:36.462213  8228 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
      "I0408 07:53:36.462213  8228 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 8\n",
      "I0408 07:53:36.463212  8228 efficientnet_model.py:144] round_filter input=32 output=64\n",
      "I0408 07:53:36.473212  8228 efficientnet_model.py:144] round_filter input=32 output=64\n",
      "I0408 07:53:36.473212  8228 efficientnet_model.py:144] round_filter input=16 output=32\n",
      "I0408 07:53:36.627213  8228 efficientnet_model.py:144] round_filter input=16 output=32\n",
      "I0408 07:53:36.627213  8228 efficientnet_model.py:144] round_filter input=24 output=48\n",
      "I0408 07:53:36.973212  8228 efficientnet_model.py:144] round_filter input=24 output=48\n",
      "I0408 07:53:36.973212  8228 efficientnet_model.py:144] round_filter input=40 output=80\n",
      "I0408 07:53:37.317212  8228 efficientnet_model.py:144] round_filter input=40 output=80\n",
      "I0408 07:53:37.318212  8228 efficientnet_model.py:144] round_filter input=80 output=160\n",
      "I0408 07:53:37.958213  8228 efficientnet_model.py:144] round_filter input=80 output=160\n",
      "I0408 07:53:37.958213  8228 efficientnet_model.py:144] round_filter input=112 output=224\n",
      "I0408 07:53:38.455213  8228 efficientnet_model.py:144] round_filter input=112 output=224\n",
      "I0408 07:53:38.455213  8228 efficientnet_model.py:144] round_filter input=192 output=384\n",
      "I0408 07:53:39.086213  8228 efficientnet_model.py:144] round_filter input=192 output=384\n",
      "I0408 07:53:39.086213  8228 efficientnet_model.py:144] round_filter input=320 output=640\n",
      "I0408 07:53:39.283212  8228 efficientnet_model.py:144] round_filter input=1280 output=2560\n",
      "I0408 07:53:39.307213  8228 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 13.95s\n",
      "I0408 07:53:39.391866  8228 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 13.95s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "I0408 07:53:39.395865  8228 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "I0408 07:53:39.396869  8228 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "I0408 07:53:39.396869  8228 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "I0408 07:53:39.397869  8228 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "[ RUN      ] ModelBuilderTF2Test.test_session\n",
      "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "I0408 07:53:39.398866  8228 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "I0408 07:53:39.398866  8228 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "I0408 07:53:39.399868  8228 test_util.py:2373] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "----------------------------------------------------------------------\n",
      "Ran 24 tests in 17.675s\n",
      "\n",
      "OK (skipped=1)\n"
     ]
    }
   ],
   "source": [
    "# From within TensorFlow/models/research/\n",
    "!python object_detection/builders/model_builder_tf2_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All tests need to pass, skipping one test is okay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gL4BBRoZuWr8",
    "outputId": "6dda655c-d7e6-4031-8459-3660ed5f8b4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mike\\Documents\\TensorFlow\\workspace\\SSD\\pre-trained-models\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users/Mike/Documents/TensorFlow/workspace/SSD/pre-trained-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MItGLVY3uWu8",
    "outputId": "b4a98c1a-6ddc-4103-cd20-bab942294f68"
   },
   "outputs": [],
   "source": [
    "import wget\n",
    "url = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz'\n",
    "filename = wget.download(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tzlPcDPLuWye",
    "outputId": "ff283587-ec3e-41fc-8bea-8e2c03eae833"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/\n",
      "x ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/\n",
      "x ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
      "x ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/checkpoint\n",
      "x ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\n",
      "x ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/pipeline.config\n",
      "x ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/\n",
      "x ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/saved_model.pb\n",
      "x ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/assets/\n",
      "x ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/\n",
      "x ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
      "x ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.index\n"
     ]
    }
   ],
   "source": [
    "!tar -xvf ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MFA0L4rmyGae",
    "outputId": "5d369ceb-fe2f-471b-9657-9b59f109484c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mike\\Documents\\TensorFlow\\workspace\\SSD\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users/Mike/Documents/TensorFlow/workspace/SSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pxst7lPT0Sby",
    "outputId": "c5aa0119-62ae-4f9e-9e42-0eca57a2dc30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 760B-EC6B\n",
      "\n",
      " Directory of C:\\Users\\Mike\\Documents\\TensorFlow\\workspace\\SSD\n",
      "\n",
      "04/07/2022  10:20 PM    <DIR>          .\n",
      "04/07/2022  10:20 PM    <DIR>          ..\n",
      "04/07/2022  05:00 PM    <DIR>          annotations\n",
      "04/07/2022  08:15 PM    <DIR>          exported-models\n",
      "03/14/2022  01:42 PM             7,605 exporter_main_v2.py\n",
      "04/07/2022  04:54 PM    <DIR>          images\n",
      "04/07/2022  04:52 PM        46,043,893 images-20220407T205130Z-001.zip\n",
      "03/14/2022  01:42 PM             4,937 model_main_tf2.py\n",
      "04/08/2022  07:34 AM    <DIR>          models\n",
      "04/07/2022  04:45 PM    <DIR>          pre-trained-models\n",
      "               3 File(s)     46,056,435 bytes\n",
      "               7 Dir(s)  166,374,354,944 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images have already been annotated, this next step can be skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mike\\Documents\\TensorFlow\\scripts\\preprocessing\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\Mike\\Documents\\TensorFlow\\scripts\\preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hU2lVZfzyuar",
    "outputId": "ac3993b2-8f22-4e66-a620-d87485982ac8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecord file: C:/Users/Mike/Documents/TensorFlow/workspace/SSD/annotations/train.record\n"
     ]
    }
   ],
   "source": [
    "# Create train data:\n",
    "!python generate_tfrecord.py \\\n",
    "-x C:/Users/Mike/Documents/TensorFlow/workspace/SSD/images/train \\ \n",
    "-l C:/Users/Mike/Documents/TensorFlow/workspace/SSD/annotations/label_map.pbtxt \\\n",
    "-o C:/Users/Mike/Documents/TensorFlow/workspace/SSD/annotations/train.record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test data:\n",
    "!python generate_tfrecord.py -x C:/Users/Mike/Documents/TensorFlow/workspace/SSD/images/test -l C:/Users/Mike/Documents/TensorFlow/workspace/SSD/annotations/label_map.pbtxt -o C:/Users/Mike/Documents/TensorFlow/workspace/SSD/annotations/test.record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "MfHABHxi56kM",
    "outputId": "d101391b-6c78-4bea-f709-92603e0dc552"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\mike\\.conda\\envs\\snakes_breed\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mike\\.conda\\envs\\snakes_breed\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\mike\\.conda\\envs\\snakes_breed\\lib\\site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\mike\\.conda\\envs\\snakes_breed\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mike\\.conda\\envs\\snakes_breed\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oQO8P8xLy6bS",
    "outputId": "82ecc083-cf71-422e-8f04-2001eb013b6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 760B-EC6B\n",
      "\n",
      " Directory of C:\\Users\\Mike\\Documents\\TensorFlow\\workspace\\SSD\\pre-trained-models\n",
      "\n",
      "04/07/2022  04:45 PM    <DIR>          .\n",
      "04/07/2022  04:45 PM    <DIR>          ..\n",
      "07/10/2020  08:17 PM    <DIR>          ssd_resnet101_v1_fpn_640x640_coco17_tpu-8\n",
      "04/07/2022  04:44 PM       386,527,459 ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz\n",
      "               1 File(s)    386,527,459 bytes\n",
      "               3 Dir(s)  169,620,484,096 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mike\\Documents\\TensorFlow\\workspace\\SSD\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users/Mike/Documents/TensorFlow/workspace/SSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mike\\Documents\\TensorFlow\\workspace\\SSD\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\Mike\\Documents\\TensorFlow\\workspace\\SSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pNVwlSCq9pr1",
    "outputId": "d28abf84-1dd4-497e-8854-5a695a137bcc",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 17:09:48.435039: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-08 17:09:48.814808: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5965 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "I0408 17:09:49.031319 11676 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "INFO:tensorflow:Maybe overwriting train_steps: None\n",
      "I0408 17:09:49.034288 11676 config_util.py:552] Maybe overwriting train_steps: None\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0408 17:09:49.034288 11676 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "WARNING:tensorflow:From C:\\Users\\Mike\\.conda\\envs\\snakes_breed\\lib\\site-packages\\object_detection\\model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "W0408 17:09:49.051294 11676 deprecation.py:337] From C:\\Users\\Mike\\.conda\\envs\\snakes_breed\\lib\\site-packages\\object_detection\\model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "INFO:tensorflow:Reading unweighted datasets: ['C:/Users/Mike/Documents/TensorFlow/workspace/SSD/annotations/train.record']\n",
      "I0408 17:09:49.054289 11676 dataset_builder.py:163] Reading unweighted datasets: ['C:/Users/Mike/Documents/TensorFlow/workspace/SSD/annotations/train.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['C:/Users/Mike/Documents/TensorFlow/workspace/SSD/annotations/train.record']\n",
      "I0408 17:09:49.054289 11676 dataset_builder.py:80] Reading record datasets for input file: ['C:/Users/Mike/Documents/TensorFlow/workspace/SSD/annotations/train.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0408 17:09:49.054289 11676 dataset_builder.py:81] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0408 17:09:49.054289 11676 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From C:\\Users\\Mike\\.conda\\envs\\snakes_breed\\lib\\site-packages\\object_detection\\builders\\dataset_builder.py:101: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "W0408 17:09:49.056289 11676 deprecation.py:337] From C:\\Users\\Mike\\.conda\\envs\\snakes_breed\\lib\\site-packages\\object_detection\\builders\\dataset_builder.py:101: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "WARNING:tensorflow:From C:\\Users\\Mike\\.conda\\envs\\snakes_breed\\lib\\site-packages\\object_detection\\builders\\dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0408 17:09:49.071288 11676 deprecation.py:337] From C:\\Users\\Mike\\.conda\\envs\\snakes_breed\\lib\\site-packages\\object_detection\\builders\\dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From C:\\Users\\Mike\\.conda\\envs\\snakes_breed\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0408 17:09:53.703787 11676 deprecation.py:337] From C:\\Users\\Mike\\.conda\\envs\\snakes_breed\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Mike\\.conda\\envs\\snakes_breed\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "W0408 17:09:55.814789 11676 deprecation.py:337] From C:\\Users\\Mike\\.conda\\envs\\snakes_breed\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Mike\\.conda\\envs\\snakes_breed\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0408 17:09:56.952787 11676 deprecation.py:337] From C:\\Users\\Mike\\.conda\\envs\\snakes_breed\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "C:\\Users\\Mike\\.conda\\envs\\snakes_breed\\lib\\site-packages\\keras\\backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
      "2022-04-08 17:10:12.810672: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0408 17:10:17.042192 11676 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0408 17:10:17.044221 11676 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0408 17:10:17.046192 11676 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0408 17:10:17.047221 11676 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0408 17:10:17.049226 11676 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0408 17:10:17.050192 11676 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0408 17:10:17.052192 11676 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0408 17:10:17.053192 11676 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0408 17:10:17.054221 11676 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0408 17:10:17.055220 11676 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "WARNING:tensorflow:From C:\\Users\\Mike\\.conda\\envs\\snakes_breed\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "W0408 17:10:18.062412  1352 deprecation.py:541] From C:\\Users\\Mike\\.conda\\envs\\snakes_breed\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "2022-04-08 17:10:47.621257: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.17GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-04-08 17:10:47.621286: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.17GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-04-08 17:10:47.730755: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.19GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-04-08 17:10:47.730781: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.19GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-04-08 17:10:47.968033: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.09GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-04-08 17:10:47.968062: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.09GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-04-08 17:10:47.976621: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.09GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-04-08 17:10:47.976644: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.09GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-04-08 17:10:48.023607: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-04-08 17:10:48.023633: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "INFO:tensorflow:Step 100 per-step time 1.498s\n",
      "I0408 17:12:47.614546 11676 model_lib_v2.py:705] Step 100 per-step time 1.498s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.544961,\n",
      " 'Loss/localization_loss': 0.4633475,\n",
      " 'Loss/regularization_loss': 0.2543772,\n",
      " 'Loss/total_loss': 1.2626857,\n",
      " 'learning_rate': 0.014666351}\n",
      "I0408 17:12:47.615551 11676 model_lib_v2.py:708] {'Loss/classification_loss': 0.544961,\n",
      " 'Loss/localization_loss': 0.4633475,\n",
      " 'Loss/regularization_loss': 0.2543772,\n",
      " 'Loss/total_loss': 1.2626857,\n",
      " 'learning_rate': 0.014666351}\n",
      "INFO:tensorflow:Step 200 per-step time 1.186s\n",
      "I0408 17:14:46.218694 11676 model_lib_v2.py:705] Step 200 per-step time 1.186s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.36636117,\n",
      " 'Loss/localization_loss': 0.21276239,\n",
      " 'Loss/regularization_loss': 0.2532297,\n",
      " 'Loss/total_loss': 0.83235323,\n",
      " 'learning_rate': 0.0159997}\n",
      "I0408 17:14:46.218694 11676 model_lib_v2.py:708] {'Loss/classification_loss': 0.36636117,\n",
      " 'Loss/localization_loss': 0.21276239,\n",
      " 'Loss/regularization_loss': 0.2532297,\n",
      " 'Loss/total_loss': 0.83235323,\n",
      " 'learning_rate': 0.0159997}\n",
      "INFO:tensorflow:Step 300 per-step time 1.185s\n",
      "I0408 17:16:44.725025 11676 model_lib_v2.py:705] Step 300 per-step time 1.185s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.39139724,\n",
      " 'Loss/localization_loss': 0.2206346,\n",
      " 'Loss/regularization_loss': 0.25197074,\n",
      " 'Loss/total_loss': 0.8640026,\n",
      " 'learning_rate': 0.01733305}\n",
      "I0408 17:16:44.725025 11676 model_lib_v2.py:708] {'Loss/classification_loss': 0.39139724,\n",
      " 'Loss/localization_loss': 0.2206346,\n",
      " 'Loss/regularization_loss': 0.25197074,\n",
      " 'Loss/total_loss': 0.8640026,\n",
      " 'learning_rate': 0.01733305}\n",
      "INFO:tensorflow:Step 400 per-step time 1.208s\n",
      "I0408 17:18:45.506525 11676 model_lib_v2.py:705] Step 400 per-step time 1.208s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.4024836,\n",
      " 'Loss/localization_loss': 0.21110491,\n",
      " 'Loss/regularization_loss': 0.25108087,\n",
      " 'Loss/total_loss': 0.8646694,\n",
      " 'learning_rate': 0.0186664}\n",
      "I0408 17:18:45.507525 11676 model_lib_v2.py:708] {'Loss/classification_loss': 0.4024836,\n",
      " 'Loss/localization_loss': 0.21110491,\n",
      " 'Loss/regularization_loss': 0.25108087,\n",
      " 'Loss/total_loss': 0.8646694,\n",
      " 'learning_rate': 0.0186664}\n",
      "INFO:tensorflow:Step 500 per-step time 1.207s\n",
      "I0408 17:20:46.229761 11676 model_lib_v2.py:705] Step 500 per-step time 1.207s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.36229557,\n",
      " 'Loss/localization_loss': 0.13719782,\n",
      " 'Loss/regularization_loss': 0.2501052,\n",
      " 'Loss/total_loss': 0.7495986,\n",
      " 'learning_rate': 0.01999975}\n",
      "I0408 17:20:46.229761 11676 model_lib_v2.py:708] {'Loss/classification_loss': 0.36229557,\n",
      " 'Loss/localization_loss': 0.13719782,\n",
      " 'Loss/regularization_loss': 0.2501052,\n",
      " 'Loss/total_loss': 0.7495986,\n",
      " 'learning_rate': 0.01999975}\n",
      "INFO:tensorflow:Step 600 per-step time 1.183s\n",
      "I0408 17:22:44.548979 11676 model_lib_v2.py:705] Step 600 per-step time 1.183s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.32647407,\n",
      " 'Loss/localization_loss': 0.17454867,\n",
      " 'Loss/regularization_loss': 0.24881935,\n",
      " 'Loss/total_loss': 0.7498421,\n",
      " 'learning_rate': 0.0213331}\n",
      "I0408 17:22:44.550020 11676 model_lib_v2.py:708] {'Loss/classification_loss': 0.32647407,\n",
      " 'Loss/localization_loss': 0.17454867,\n",
      " 'Loss/regularization_loss': 0.24881935,\n",
      " 'Loss/total_loss': 0.7498421,\n",
      " 'learning_rate': 0.0213331}\n",
      "INFO:tensorflow:Step 700 per-step time 1.210s\n",
      "I0408 17:24:45.503441 11676 model_lib_v2.py:705] Step 700 per-step time 1.210s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.3255831,\n",
      " 'Loss/localization_loss': 0.13617858,\n",
      " 'Loss/regularization_loss': 0.24755533,\n",
      " 'Loss/total_loss': 0.70931697,\n",
      " 'learning_rate': 0.02266645}\n",
      "I0408 17:24:45.503441 11676 model_lib_v2.py:708] {'Loss/classification_loss': 0.3255831,\n",
      " 'Loss/localization_loss': 0.13617858,\n",
      " 'Loss/regularization_loss': 0.24755533,\n",
      " 'Loss/total_loss': 0.70931697,\n",
      " 'learning_rate': 0.02266645}\n",
      "INFO:tensorflow:Step 800 per-step time 1.228s\n",
      "I0408 17:26:48.285913 11676 model_lib_v2.py:705] Step 800 per-step time 1.228s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.47882175,\n",
      " 'Loss/localization_loss': 0.38614237,\n",
      " 'Loss/regularization_loss': 0.24640653,\n",
      " 'Loss/total_loss': 1.1113707,\n",
      " 'learning_rate': 0.023999799}\n",
      "I0408 17:26:48.285913 11676 model_lib_v2.py:708] {'Loss/classification_loss': 0.47882175,\n",
      " 'Loss/localization_loss': 0.38614237,\n",
      " 'Loss/regularization_loss': 0.24640653,\n",
      " 'Loss/total_loss': 1.1113707,\n",
      " 'learning_rate': 0.023999799}\n",
      "INFO:tensorflow:Step 900 per-step time 1.192s\n",
      "I0408 17:28:47.497519 11676 model_lib_v2.py:705] Step 900 per-step time 1.192s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.2851903,\n",
      " 'Loss/localization_loss': 0.12803233,\n",
      " 'Loss/regularization_loss': 0.24536264,\n",
      " 'Loss/total_loss': 0.6585853,\n",
      " 'learning_rate': 0.025333151}\n",
      "I0408 17:28:47.497519 11676 model_lib_v2.py:708] {'Loss/classification_loss': 0.2851903,\n",
      " 'Loss/localization_loss': 0.12803233,\n",
      " 'Loss/regularization_loss': 0.24536264,\n",
      " 'Loss/total_loss': 0.6585853,\n",
      " 'learning_rate': 0.025333151}\n",
      "INFO:tensorflow:Step 1000 per-step time 1.190s\n",
      "I0408 17:30:46.450621 11676 model_lib_v2.py:705] Step 1000 per-step time 1.190s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.27241012,\n",
      " 'Loss/localization_loss': 0.08057206,\n",
      " 'Loss/regularization_loss': 0.24494061,\n",
      " 'Loss/total_loss': 0.5979228,\n",
      " 'learning_rate': 0.0266665}\n",
      "I0408 17:30:46.450621 11676 model_lib_v2.py:708] {'Loss/classification_loss': 0.27241012,\n",
      " 'Loss/localization_loss': 0.08057206,\n",
      " 'Loss/regularization_loss': 0.24494061,\n",
      " 'Loss/total_loss': 0.5979228,\n",
      " 'learning_rate': 0.0266665}\n",
      "INFO:tensorflow:Step 1100 per-step time 1.204s\n",
      "I0408 17:32:46.814056 11676 model_lib_v2.py:705] Step 1100 per-step time 1.204s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.35869226,\n",
      " 'Loss/localization_loss': 0.24480686,\n",
      " 'Loss/regularization_loss': 0.24393898,\n",
      " 'Loss/total_loss': 0.8474381,\n",
      " 'learning_rate': 0.02799985}\n",
      "I0408 17:32:46.814056 11676 model_lib_v2.py:708] {'Loss/classification_loss': 0.35869226,\n",
      " 'Loss/localization_loss': 0.24480686,\n",
      " 'Loss/regularization_loss': 0.24393898,\n",
      " 'Loss/total_loss': 0.8474381,\n",
      " 'learning_rate': 0.02799985}\n",
      "INFO:tensorflow:Step 1200 per-step time 1.185s\n",
      "I0408 17:34:45.333720 11676 model_lib_v2.py:705] Step 1200 per-step time 1.185s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.32953143,\n",
      " 'Loss/localization_loss': 0.13396661,\n",
      " 'Loss/regularization_loss': 0.24353077,\n",
      " 'Loss/total_loss': 0.7070288,\n",
      " 'learning_rate': 0.0293332}\n",
      "I0408 17:34:45.333720 11676 model_lib_v2.py:708] {'Loss/classification_loss': 0.32953143,\n",
      " 'Loss/localization_loss': 0.13396661,\n",
      " 'Loss/regularization_loss': 0.24353077,\n",
      " 'Loss/total_loss': 0.7070288,\n",
      " 'learning_rate': 0.0293332}\n",
      "INFO:tensorflow:Step 1300 per-step time 1.187s\n",
      "I0408 17:36:44.036084 11676 model_lib_v2.py:705] Step 1300 per-step time 1.187s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.3951494,\n",
      " 'Loss/localization_loss': 0.19557977,\n",
      " 'Loss/regularization_loss': 0.242742,\n",
      " 'Loss/total_loss': 0.8334712,\n",
      " 'learning_rate': 0.03066655}\n",
      "I0408 17:36:44.036084 11676 model_lib_v2.py:708] {'Loss/classification_loss': 0.3951494,\n",
      " 'Loss/localization_loss': 0.19557977,\n",
      " 'Loss/regularization_loss': 0.242742,\n",
      " 'Loss/total_loss': 0.8334712,\n",
      " 'learning_rate': 0.03066655}\n",
      "INFO:tensorflow:Step 1400 per-step time 1.187s\n",
      "I0408 17:38:42.756567 11676 model_lib_v2.py:705] Step 1400 per-step time 1.187s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.45321405,\n",
      " 'Loss/localization_loss': 0.44457197,\n",
      " 'Loss/regularization_loss': 0.24249017,\n",
      " 'Loss/total_loss': 1.1402762,\n",
      " 'learning_rate': 0.0319999}\n",
      "I0408 17:38:42.756567 11676 model_lib_v2.py:708] {'Loss/classification_loss': 0.45321405,\n",
      " 'Loss/localization_loss': 0.44457197,\n",
      " 'Loss/regularization_loss': 0.24249017,\n",
      " 'Loss/total_loss': 1.1402762,\n",
      " 'learning_rate': 0.0319999}\n",
      "INFO:tensorflow:Step 1500 per-step time 1.225s\n",
      "I0408 17:40:45.243891 11676 model_lib_v2.py:705] Step 1500 per-step time 1.225s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.2902313,\n",
      " 'Loss/localization_loss': 0.19030839,\n",
      " 'Loss/regularization_loss': 0.2423093,\n",
      " 'Loss/total_loss': 0.72284895,\n",
      " 'learning_rate': 0.03333325}\n",
      "I0408 17:40:45.243891 11676 model_lib_v2.py:708] {'Loss/classification_loss': 0.2902313,\n",
      " 'Loss/localization_loss': 0.19030839,\n",
      " 'Loss/regularization_loss': 0.2423093,\n",
      " 'Loss/total_loss': 0.72284895,\n",
      " 'learning_rate': 0.03333325}\n",
      "INFO:tensorflow:Step 1600 per-step time 1.214s\n",
      "I0408 17:42:46.604011 11676 model_lib_v2.py:705] Step 1600 per-step time 1.214s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.32005972,\n",
      " 'Loss/localization_loss': 0.09338898,\n",
      " 'Loss/regularization_loss': 0.24174672,\n",
      " 'Loss/total_loss': 0.6551954,\n",
      " 'learning_rate': 0.034666598}\n",
      "I0408 17:42:46.604011 11676 model_lib_v2.py:708] {'Loss/classification_loss': 0.32005972,\n",
      " 'Loss/localization_loss': 0.09338898,\n",
      " 'Loss/regularization_loss': 0.24174672,\n",
      " 'Loss/total_loss': 0.6551954,\n",
      " 'learning_rate': 0.034666598}\n",
      "INFO:tensorflow:Step 1700 per-step time 1.212s\n",
      "I0408 17:44:47.781513 11676 model_lib_v2.py:705] Step 1700 per-step time 1.212s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.27972928,\n",
      " 'Loss/localization_loss': 0.12777975,\n",
      " 'Loss/regularization_loss': 0.24188936,\n",
      " 'Loss/total_loss': 0.6493983,\n",
      " 'learning_rate': 0.03599995}\n",
      "I0408 17:44:47.782513 11676 model_lib_v2.py:708] {'Loss/classification_loss': 0.27972928,\n",
      " 'Loss/localization_loss': 0.12777975,\n",
      " 'Loss/regularization_loss': 0.24188936,\n",
      " 'Loss/total_loss': 0.6493983,\n",
      " 'learning_rate': 0.03599995}\n",
      "INFO:tensorflow:Step 1800 per-step time 1.187s\n",
      "I0408 17:46:46.459084 11676 model_lib_v2.py:705] Step 1800 per-step time 1.187s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.25163397,\n",
      " 'Loss/localization_loss': 0.09919674,\n",
      " 'Loss/regularization_loss': 0.24209315,\n",
      " 'Loss/total_loss': 0.5929239,\n",
      " 'learning_rate': 0.037333302}\n",
      "I0408 17:46:46.460084 11676 model_lib_v2.py:708] {'Loss/classification_loss': 0.25163397,\n",
      " 'Loss/localization_loss': 0.09919674,\n",
      " 'Loss/regularization_loss': 0.24209315,\n",
      " 'Loss/total_loss': 0.5929239,\n",
      " 'learning_rate': 0.037333302}\n",
      "INFO:tensorflow:Step 1900 per-step time 1.188s\n",
      "I0408 17:48:45.246277 11676 model_lib_v2.py:705] Step 1900 per-step time 1.188s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.28680325,\n",
      " 'Loss/localization_loss': 0.11940967,\n",
      " 'Loss/regularization_loss': 0.24209268,\n",
      " 'Loss/total_loss': 0.6483056,\n",
      " 'learning_rate': 0.03866665}\n",
      "I0408 17:48:45.246277 11676 model_lib_v2.py:708] {'Loss/classification_loss': 0.28680325,\n",
      " 'Loss/localization_loss': 0.11940967,\n",
      " 'Loss/regularization_loss': 0.24209268,\n",
      " 'Loss/total_loss': 0.6483056,\n",
      " 'learning_rate': 0.03866665}\n",
      "INFO:tensorflow:Step 2000 per-step time 1.207s\n",
      "I0408 17:50:45.983724 11676 model_lib_v2.py:705] Step 2000 per-step time 1.207s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.27846023,\n",
      " 'Loss/localization_loss': 0.14221938,\n",
      " 'Loss/regularization_loss': 0.2423144,\n",
      " 'Loss/total_loss': 0.66299397,\n",
      " 'learning_rate': 0.04}\n",
      "I0408 17:50:45.984723 11676 model_lib_v2.py:708] {'Loss/classification_loss': 0.27846023,\n",
      " 'Loss/localization_loss': 0.14221938,\n",
      " 'Loss/regularization_loss': 0.2423144,\n",
      " 'Loss/total_loss': 0.66299397,\n",
      " 'learning_rate': 0.04}\n",
      "INFO:tensorflow:Step 2100 per-step time 1.221s\n",
      "I0408 17:52:48.125896 11676 model_lib_v2.py:705] Step 2100 per-step time 1.221s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.35982403,\n",
      " 'Loss/localization_loss': 0.12078931,\n",
      " 'Loss/regularization_loss': 0.24262506,\n",
      " 'Loss/total_loss': 0.72323835,\n",
      " 'learning_rate': 0.039998136}\n",
      "I0408 17:52:48.125896 11676 model_lib_v2.py:708] {'Loss/classification_loss': 0.35982403,\n",
      " 'Loss/localization_loss': 0.12078931,\n",
      " 'Loss/regularization_loss': 0.24262506,\n",
      " 'Loss/total_loss': 0.72323835,\n",
      " 'learning_rate': 0.039998136}\n",
      "INFO:tensorflow:Step 2200 per-step time 1.216s\n",
      "I0408 17:54:49.706052 11676 model_lib_v2.py:705] Step 2200 per-step time 1.216s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.27146766,\n",
      " 'Loss/localization_loss': 0.15338807,\n",
      " 'Loss/regularization_loss': 0.24262,\n",
      " 'Loss/total_loss': 0.66747576,\n",
      " 'learning_rate': 0.039992537}\n",
      "I0408 17:54:49.706052 11676 model_lib_v2.py:708] {'Loss/classification_loss': 0.27146766,\n",
      " 'Loss/localization_loss': 0.15338807,\n",
      " 'Loss/regularization_loss': 0.24262,\n",
      " 'Loss/total_loss': 0.66747576,\n",
      " 'learning_rate': 0.039992537}\n",
      "INFO:tensorflow:Step 2300 per-step time 1.189s\n",
      "I0408 17:56:48.629636 11676 model_lib_v2.py:705] Step 2300 per-step time 1.189s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.2342131,\n",
      " 'Loss/localization_loss': 0.08777574,\n",
      " 'Loss/regularization_loss': 0.24344067,\n",
      " 'Loss/total_loss': 0.5654295,\n",
      " 'learning_rate': 0.03998321}\n",
      "I0408 17:56:48.629636 11676 model_lib_v2.py:708] {'Loss/classification_loss': 0.2342131,\n",
      " 'Loss/localization_loss': 0.08777574,\n",
      " 'Loss/regularization_loss': 0.24344067,\n",
      " 'Loss/total_loss': 0.5654295,\n",
      " 'learning_rate': 0.03998321}\n",
      "INFO:tensorflow:Step 2400 per-step time 1.185s\n",
      "I0408 17:58:47.145562 11676 model_lib_v2.py:705] Step 2400 per-step time 1.185s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.30166042,\n",
      " 'Loss/localization_loss': 0.16337095,\n",
      " 'Loss/regularization_loss': 0.24413686,\n",
      " 'Loss/total_loss': 0.70916826,\n",
      " 'learning_rate': 0.039970152}\n",
      "I0408 17:58:47.145562 11676 model_lib_v2.py:708] {'Loss/classification_loss': 0.30166042,\n",
      " 'Loss/localization_loss': 0.16337095,\n",
      " 'Loss/regularization_loss': 0.24413686,\n",
      " 'Loss/total_loss': 0.70916826,\n",
      " 'learning_rate': 0.039970152}\n",
      "INFO:tensorflow:Step 2500 per-step time 1.187s\n",
      "I0408 18:00:45.811176 11676 model_lib_v2.py:705] Step 2500 per-step time 1.187s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.25370985,\n",
      " 'Loss/localization_loss': 0.12864594,\n",
      " 'Loss/regularization_loss': 0.24298309,\n",
      " 'Loss/total_loss': 0.6253389,\n",
      " 'learning_rate': 0.039953373}\n",
      "I0408 18:00:45.811176 11676 model_lib_v2.py:708] {'Loss/classification_loss': 0.25370985,\n",
      " 'Loss/localization_loss': 0.12864594,\n",
      " 'Loss/regularization_loss': 0.24298309,\n",
      " 'Loss/total_loss': 0.6253389,\n",
      " 'learning_rate': 0.039953373}\n",
      "INFO:tensorflow:Step 2600 per-step time 1.199s\n",
      "I0408 18:02:45.749508 11676 model_lib_v2.py:705] Step 2600 per-step time 1.199s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.2460756,\n",
      " 'Loss/localization_loss': 0.10386514,\n",
      " 'Loss/regularization_loss': 0.24262422,\n",
      " 'Loss/total_loss': 0.59256494,\n",
      " 'learning_rate': 0.03993287}\n",
      "I0408 18:02:45.749508 11676 model_lib_v2.py:708] {'Loss/classification_loss': 0.2460756,\n",
      " 'Loss/localization_loss': 0.10386514,\n",
      " 'Loss/regularization_loss': 0.24262422,\n",
      " 'Loss/total_loss': 0.59256494,\n",
      " 'learning_rate': 0.03993287}\n",
      "INFO:tensorflow:Step 2700 per-step time 1.281s\n",
      "I0408 18:04:53.861133 11676 model_lib_v2.py:705] Step 2700 per-step time 1.281s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.22401252,\n",
      " 'Loss/localization_loss': 0.09036641,\n",
      " 'Loss/regularization_loss': 0.24256857,\n",
      " 'Loss/total_loss': 0.5569475,\n",
      " 'learning_rate': 0.039908648}\n",
      "I0408 18:04:53.862133 11676 model_lib_v2.py:708] {'Loss/classification_loss': 0.22401252,\n",
      " 'Loss/localization_loss': 0.09036641,\n",
      " 'Loss/regularization_loss': 0.24256857,\n",
      " 'Loss/total_loss': 0.5569475,\n",
      " 'learning_rate': 0.039908648}\n",
      "INFO:tensorflow:Step 2800 per-step time 1.535s\n",
      "I0408 18:07:27.329694 11676 model_lib_v2.py:705] Step 2800 per-step time 1.535s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.27588555,\n",
      " 'Loss/localization_loss': 0.208824,\n",
      " 'Loss/regularization_loss': 0.24233451,\n",
      " 'Loss/total_loss': 0.72704405,\n",
      " 'learning_rate': 0.039880715}\n",
      "I0408 18:07:27.329694 11676 model_lib_v2.py:708] {'Loss/classification_loss': 0.27588555,\n",
      " 'Loss/localization_loss': 0.208824,\n",
      " 'Loss/regularization_loss': 0.24233451,\n",
      " 'Loss/total_loss': 0.72704405,\n",
      " 'learning_rate': 0.039880715}\n",
      "INFO:tensorflow:Step 2900 per-step time 2.741s\n",
      "I0408 18:12:01.437743 11676 model_lib_v2.py:705] Step 2900 per-step time 2.741s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.24563284,\n",
      " 'Loss/localization_loss': 0.09699761,\n",
      " 'Loss/regularization_loss': 0.24229263,\n",
      " 'Loss/total_loss': 0.5849231,\n",
      " 'learning_rate': 0.039849065}\n",
      "I0408 18:12:01.438761 11676 model_lib_v2.py:708] {'Loss/classification_loss': 0.24563284,\n",
      " 'Loss/localization_loss': 0.09699761,\n",
      " 'Loss/regularization_loss': 0.24229263,\n",
      " 'Loss/total_loss': 0.5849231,\n",
      " 'learning_rate': 0.039849065}\n",
      "INFO:tensorflow:Step 3000 per-step time 1.435s\n",
      "I0408 18:14:24.952530 11676 model_lib_v2.py:705] Step 3000 per-step time 1.435s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.25648117,\n",
      " 'Loss/localization_loss': 0.07442177,\n",
      " 'Loss/regularization_loss': 0.24272344,\n",
      " 'Loss/total_loss': 0.5736264,\n",
      " 'learning_rate': 0.03981372}\n",
      "I0408 18:14:24.952530 11676 model_lib_v2.py:708] {'Loss/classification_loss': 0.25648117,\n",
      " 'Loss/localization_loss': 0.07442177,\n",
      " 'Loss/regularization_loss': 0.24272344,\n",
      " 'Loss/total_loss': 0.5736264,\n",
      " 'learning_rate': 0.03981372}\n",
      "INFO:tensorflow:Step 3100 per-step time 1.825s\n",
      "I0408 18:17:27.419502 11676 model_lib_v2.py:705] Step 3100 per-step time 1.825s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.21025091,\n",
      " 'Loss/localization_loss': 0.122216694,\n",
      " 'Loss/regularization_loss': 0.24310586,\n",
      " 'Loss/total_loss': 0.57557344,\n",
      " 'learning_rate': 0.03977467}\n",
      "I0408 18:17:27.419502 11676 model_lib_v2.py:708] {'Loss/classification_loss': 0.21025091,\n",
      " 'Loss/localization_loss': 0.122216694,\n",
      " 'Loss/regularization_loss': 0.24310586,\n",
      " 'Loss/total_loss': 0.57557344,\n",
      " 'learning_rate': 0.03977467}\n",
      "INFO:tensorflow:Step 3200 per-step time 1.647s\n",
      "I0408 18:20:12.165625 11676 model_lib_v2.py:705] Step 3200 per-step time 1.647s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.2563811,\n",
      " 'Loss/localization_loss': 0.12055439,\n",
      " 'Loss/regularization_loss': 0.24229017,\n",
      " 'Loss/total_loss': 0.6192256,\n",
      " 'learning_rate': 0.03973194}\n",
      "I0408 18:20:12.165625 11676 model_lib_v2.py:708] {'Loss/classification_loss': 0.2563811,\n",
      " 'Loss/localization_loss': 0.12055439,\n",
      " 'Loss/regularization_loss': 0.24229017,\n",
      " 'Loss/total_loss': 0.6192256,\n",
      " 'learning_rate': 0.03973194}\n",
      "INFO:tensorflow:Step 3300 per-step time 1.445s\n",
      "I0408 18:22:36.619597 11676 model_lib_v2.py:705] Step 3300 per-step time 1.445s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.23926863,\n",
      " 'Loss/localization_loss': 0.10973494,\n",
      " 'Loss/regularization_loss': 0.24152412,\n",
      " 'Loss/total_loss': 0.5905277,\n",
      " 'learning_rate': 0.03968552}\n",
      "I0408 18:22:36.619597 11676 model_lib_v2.py:708] {'Loss/classification_loss': 0.23926863,\n",
      " 'Loss/localization_loss': 0.10973494,\n",
      " 'Loss/regularization_loss': 0.24152412,\n",
      " 'Loss/total_loss': 0.5905277,\n",
      " 'learning_rate': 0.03968552}\n",
      "INFO:tensorflow:Step 3400 per-step time 1.515s\n",
      "I0408 18:25:08.158849 11676 model_lib_v2.py:705] Step 3400 per-step time 1.515s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.19243805,\n",
      " 'Loss/localization_loss': 0.117021136,\n",
      " 'Loss/regularization_loss': 0.24119161,\n",
      " 'Loss/total_loss': 0.5506508,\n",
      " 'learning_rate': 0.039635435}\n",
      "I0408 18:25:08.159849 11676 model_lib_v2.py:708] {'Loss/classification_loss': 0.19243805,\n",
      " 'Loss/localization_loss': 0.117021136,\n",
      " 'Loss/regularization_loss': 0.24119161,\n",
      " 'Loss/total_loss': 0.5506508,\n",
      " 'learning_rate': 0.039635435}\n",
      "INFO:tensorflow:Step 3500 per-step time 1.557s\n",
      "I0408 18:27:43.819468 11676 model_lib_v2.py:705] Step 3500 per-step time 1.557s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.19259243,\n",
      " 'Loss/localization_loss': 0.091046125,\n",
      " 'Loss/regularization_loss': 0.2407764,\n",
      " 'Loss/total_loss': 0.52441496,\n",
      " 'learning_rate': 0.03958168}\n",
      "I0408 18:27:43.820469 11676 model_lib_v2.py:708] {'Loss/classification_loss': 0.19259243,\n",
      " 'Loss/localization_loss': 0.091046125,\n",
      " 'Loss/regularization_loss': 0.2407764,\n",
      " 'Loss/total_loss': 0.52441496,\n",
      " 'learning_rate': 0.03958168}\n",
      "INFO:tensorflow:Step 3600 per-step time 1.558s\n",
      "I0408 18:30:19.642651 11676 model_lib_v2.py:705] Step 3600 per-step time 1.558s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.14525458,\n",
      " 'Loss/localization_loss': 0.053605914,\n",
      " 'Loss/regularization_loss': 0.24079002,\n",
      " 'Loss/total_loss': 0.43965054,\n",
      " 'learning_rate': 0.039524276}\n",
      "I0408 18:30:19.642651 11676 model_lib_v2.py:708] {'Loss/classification_loss': 0.14525458,\n",
      " 'Loss/localization_loss': 0.053605914,\n",
      " 'Loss/regularization_loss': 0.24079002,\n",
      " 'Loss/total_loss': 0.43965054,\n",
      " 'learning_rate': 0.039524276}\n",
      "INFO:tensorflow:Step 3700 per-step time 1.664s\n",
      "I0408 18:33:06.091450 11676 model_lib_v2.py:705] Step 3700 per-step time 1.664s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.16998264,\n",
      " 'Loss/localization_loss': 0.07342255,\n",
      " 'Loss/regularization_loss': 0.24022597,\n",
      " 'Loss/total_loss': 0.48363116,\n",
      " 'learning_rate': 0.03946323}\n",
      "I0408 18:33:06.092450 11676 model_lib_v2.py:708] {'Loss/classification_loss': 0.16998264,\n",
      " 'Loss/localization_loss': 0.07342255,\n",
      " 'Loss/regularization_loss': 0.24022597,\n",
      " 'Loss/total_loss': 0.48363116,\n",
      " 'learning_rate': 0.03946323}\n",
      "INFO:tensorflow:Step 3800 per-step time 1.737s\n",
      "I0408 18:35:59.752331 11676 model_lib_v2.py:705] Step 3800 per-step time 1.737s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.16279136,\n",
      " 'Loss/localization_loss': 0.0873095,\n",
      " 'Loss/regularization_loss': 0.23989621,\n",
      " 'Loss/total_loss': 0.48999706,\n",
      " 'learning_rate': 0.039398547}\n",
      "I0408 18:35:59.753330 11676 model_lib_v2.py:708] {'Loss/classification_loss': 0.16279136,\n",
      " 'Loss/localization_loss': 0.0873095,\n",
      " 'Loss/regularization_loss': 0.23989621,\n",
      " 'Loss/total_loss': 0.48999706,\n",
      " 'learning_rate': 0.039398547}\n",
      "INFO:tensorflow:Step 3900 per-step time 1.476s\n",
      "I0408 18:38:27.366012 11676 model_lib_v2.py:705] Step 3900 per-step time 1.476s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.23193944,\n",
      " 'Loss/localization_loss': 0.09797503,\n",
      " 'Loss/regularization_loss': 0.24025945,\n",
      " 'Loss/total_loss': 0.5701739,\n",
      " 'learning_rate': 0.039330248}\n",
      "I0408 18:38:27.366012 11676 model_lib_v2.py:708] {'Loss/classification_loss': 0.23193944,\n",
      " 'Loss/localization_loss': 0.09797503,\n",
      " 'Loss/regularization_loss': 0.24025945,\n",
      " 'Loss/total_loss': 0.5701739,\n",
      " 'learning_rate': 0.039330248}\n",
      "INFO:tensorflow:Step 4000 per-step time 1.233s\n",
      "I0408 18:40:30.684685 11676 model_lib_v2.py:705] Step 4000 per-step time 1.233s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.1841317,\n",
      " 'Loss/localization_loss': 0.05939169,\n",
      " 'Loss/regularization_loss': 0.24015862,\n",
      " 'Loss/total_loss': 0.48368198,\n",
      " 'learning_rate': 0.039258346}\n",
      "I0408 18:40:30.684685 11676 model_lib_v2.py:708] {'Loss/classification_loss': 0.1841317,\n",
      " 'Loss/localization_loss': 0.05939169,\n",
      " 'Loss/regularization_loss': 0.24015862,\n",
      " 'Loss/total_loss': 0.48368198,\n",
      " 'learning_rate': 0.039258346}\n"
     ]
    }
   ],
   "source": [
    "!python model_main_tf2.py --model_dir=C:/Users/Mike/Documents/TensorFlow/workspace/SSD/models/ssd_resnet101 \\\n",
    "--pipeline_config_path=C:/Users/Mike/Documents/TensorFlow/workspace/SSD/models/pipeline.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "TlRqjT4AFOhv",
    "outputId": "a77528bd-f60a-4846-cf1a-f2b7eb8d3513",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.30s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.07s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.288\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.519\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.292\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.294\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.494\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.565\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.596\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
      "W0408 19:04:15.854352 12172 model_lib_v2.py:1089] Forced number of epochs for all eval validations to be 1.\n",
      "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n",
      "I0408 19:04:15.854352 12172 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0408 19:04:15.854352 12172 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
      "I0408 19:04:15.855351 12172 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
      "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "W0408 19:04:15.855351 12172 model_lib_v2.py:1107] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "INFO:tensorflow:Reading unweighted datasets: ['C:/Users/Mike/Documents/TensorFlow/workspace/SSD/annotations/test.record']\n",
      "I0408 19:04:16.430180 12172 dataset_builder.py:163] Reading unweighted datasets: ['C:/Users/Mike/Documents/TensorFlow/workspace/SSD/annotations/test.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['C:/Users/Mike/Documents/TensorFlow/workspace/SSD/annotations/test.record']\n",
      "I0408 19:04:16.430180 12172 dataset_builder.py:80] Reading record datasets for input file: ['C:/Users/Mike/Documents/TensorFlow/workspace/SSD/annotations/test.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0408 19:04:16.430180 12172 dataset_builder.py:81] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0408 19:04:16.430180 12172 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From C:\\Users\\Mike\\.conda\\envs\\snakes_breed\\lib\\site-packages\\object_detection\\builders\\dataset_builder.py:101: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "W0408 19:04:16.431179 12172 deprecation.py:337] From C:\\Users\\Mike\\.conda\\envs\\snakes_breed\\lib\\site-packages\\object_detection\\builders\\dataset_builder.py:101: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "WARNING:tensorflow:From C:\\Users\\Mike\\.conda\\envs\\snakes_breed\\lib\\site-packages\\object_detection\\builders\\dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0408 19:04:16.448163 12172 deprecation.py:337] From C:\\Users\\Mike\\.conda\\envs\\snakes_breed\\lib\\site-packages\\object_detection\\builders\\dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From C:\\Users\\Mike\\.conda\\envs\\snakes_breed\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0408 19:04:19.194214 12172 deprecation.py:337] From C:\\Users\\Mike\\.conda\\envs\\snakes_breed\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Mike\\.conda\\envs\\snakes_breed\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0408 19:04:20.000215 12172 deprecation.py:337] From C:\\Users\\Mike\\.conda\\envs\\snakes_breed\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Waiting for new checkpoint at C:/Users/Mike/Documents/TensorFlow/workspace/SSD/models/ssd_resnet101\n",
      "I0408 19:04:21.816214 12172 checkpoint_utils.py:136] Waiting for new checkpoint at C:/Users/Mike/Documents/TensorFlow/workspace/SSD/models/ssd_resnet101\n",
      "INFO:tensorflow:Found new checkpoint at C:/Users/Mike/Documents/TensorFlow/workspace/SSD/models/ssd_resnet101\\ckpt-5\n",
      "I0408 19:04:21.817215 12172 checkpoint_utils.py:145] Found new checkpoint at C:/Users/Mike/Documents/TensorFlow/workspace/SSD/models/ssd_resnet101\\ckpt-5\n",
      "C:\\Users\\Mike\\.conda\\envs\\snakes_breed\\lib\\site-packages\\keras\\backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
      "WARNING:tensorflow:From C:\\Users\\Mike\\.conda\\envs\\snakes_breed\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0408 19:04:41.200387 12172 deprecation.py:337] From C:\\Users\\Mike\\.conda\\envs\\snakes_breed\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Finished eval step 0\n",
      "I0408 19:04:41.209387 12172 model_lib_v2.py:966] Finished eval step 0\n",
      "WARNING:tensorflow:From C:\\Users\\Mike\\.conda\\envs\\snakes_breed\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "W0408 19:04:41.301388 12172 deprecation.py:337] From C:\\Users\\Mike\\.conda\\envs\\snakes_breed\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "INFO:tensorflow:Performing evaluation on 100 images.\n",
      "I0408 19:04:50.115677 12172 coco_evaluation.py:293] Performing evaluation on 100 images.\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "I0408 19:04:50.115677 12172 coco_tools.py:116] Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "I0408 19:04:50.120678 12172 coco_tools.py:138] DONE (t=0.00s)\n",
      "INFO:tensorflow:Eval metrics at step 4000\n",
      "I0408 19:04:50.494678 12172 model_lib_v2.py:1015] Eval metrics at step 4000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.287810\n",
      "I0408 19:04:50.568723 12172 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.287810\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.519050\n",
      "I0408 19:04:50.574682 12172 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.519050\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.292408\n",
      "I0408 19:04:50.581685 12172 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.292408\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): -1.000000\n",
      "I0408 19:04:50.586665 12172 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): -1.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.000000\n",
      "I0408 19:04:50.590665 12172 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): 0.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.293850\n",
      "I0408 19:04:50.593665 12172 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): 0.293850\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.493913\n",
      "I0408 19:04:50.596681 12172 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.493913\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.565450\n",
      "I0408 19:04:50.598664 12172 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.565450\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.596350\n",
      "I0408 19:04:50.600664 12172 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.596350\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
      "I0408 19:04:50.602664 12172 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.000000\n",
      "I0408 19:04:50.604664 12172 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.607623\n",
      "I0408 19:04:50.607664 12172 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): 0.607623\n",
      "INFO:tensorflow:\t+ Loss/localization_loss: 0.232933\n",
      "I0408 19:04:50.608663 12172 model_lib_v2.py:1018] \t+ Loss/localization_loss: 0.232933\n",
      "INFO:tensorflow:\t+ Loss/classification_loss: 0.464044\n",
      "I0408 19:04:50.610663 12172 model_lib_v2.py:1018] \t+ Loss/classification_loss: 0.464044\n",
      "INFO:tensorflow:\t+ Loss/regularization_loss: 0.240150\n",
      "I0408 19:04:50.611664 12172 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 0.240150\n",
      "INFO:tensorflow:\t+ Loss/total_loss: 0.937127\n",
      "I0408 19:04:50.613670 12172 model_lib_v2.py:1018] \t+ Loss/total_loss: 0.937127\n",
      "INFO:tensorflow:Exiting evaluation at step 4000\n",
      "I0408 19:04:50.721662 12172 model_lib_v2.py:1169] Exiting evaluation at step 4000\n"
     ]
    }
   ],
   "source": [
    "!python model_main_tf2.py \\\n",
    "--model_dir=C:/Users/Mike/Documents/TensorFlow/workspace/SSD/models/ssd_resnet101 \\\n",
    "--pipeline_config_path=C:/Users/Mike/Documents/TensorFlow/workspace/SSD/models/pipeline.config \\\n",
    "--checkpoint_dir=C:/Users/Mike/Documents/TensorFlow/workspace/SSD/models/ssd_resnet101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UeI2URnR9zhw",
    "outputId": "9f3a2fb3-389d-425d-c80f-ad97f04b235b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Mike\\.conda\\envs\\snakes_breed\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "W0408 19:05:30.034579 16500 deprecation.py:610] From C:\\Users\\Mike\\.conda\\envs\\snakes_breed\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x000001DE106F3130>, because it is not built.\n",
      "W0408 19:05:45.553157 16500 save_impl.py:71] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x000001DE106F3130>, because it is not built.\n",
      "W0408 19:05:57.611629 16500 save.py:260] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalClassHead_layer_call_fn while saving (showing 5 of 208). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: C:/Users/Mike/Documents/TensorFlow/workspace/SSD/exported-models/my_model\\saved_model\\assets\n",
      "I0408 19:06:02.160487 16500 builder_impl.py:779] Assets written to: C:/Users/Mike/Documents/TensorFlow/workspace/SSD/exported-models/my_model\\saved_model\\assets\n",
      "INFO:tensorflow:Writing pipeline config file to C:/Users/Mike/Documents/TensorFlow/workspace/SSD/exported-models/my_model\\pipeline.config\n",
      "I0408 19:06:02.661509 16500 config_util.py:253] Writing pipeline config file to C:/Users/Mike/Documents/TensorFlow/workspace/SSD/exported-models/my_model\\pipeline.config\n"
     ]
    }
   ],
   "source": [
    "!python exporter_main_v2.py --input_type image_tensor --pipeline_config_path C:/Users/Mike/Documents/TensorFlow/workspace/SSD/models/pipeline.config --trained_checkpoint_dir C:/Users/Mike/Documents/TensorFlow/workspace/SSD/models/ssd_resnet101/ --output_directory C:/Users/Mike/Documents/TensorFlow/workspace/SSD/exported-models/my_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GIIKwpxtGAhK"
   },
   "source": [
    "Inferencing My Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "id": "spZJ4ms3FqRT",
    "outputId": "7144443c-1691-45e5-d26e-7872a5a62d73",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...Done! Took 8.842968225479126 seconds\n",
      "Running inference for C:/Users/Mike/Documents/TensorFlow/workspace/SSD/images/test/0a006d8501f3ec1dd144b9c68dc9f542.JPG... Done\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n",
    "\n",
    "# PROVIDE PATH TO IMAGE DIRECTORY\n",
    "IMAGE_PATHS = 'C:/Users/Mike/Documents/TensorFlow/workspace/SSD/images/test/0a006d8501f3ec1dd144b9c68dc9f542.JPG'\n",
    "\n",
    "\n",
    "# PROVIDE PATH TO MODEL DIRECTORY\n",
    "PATH_TO_MODEL_DIR = 'C:/Users/Mike/Documents/TensorFlow/workspace/SSD/exported-models/my_model'\n",
    "\n",
    "# PROVIDE PATH TO LABEL MAP\n",
    "PATH_TO_LABELS = 'C:/Users/Mike/Documents/TensorFlow/workspace/SSD/annotations/label_map.pbtxt'\n",
    "\n",
    "\n",
    "# PROVIDE THE MINIMUM CONFIDENCE THRESHOLD\n",
    "MIN_CONF_THRESH = float(0.60)\n",
    "\n",
    "# LOAD THE MODEL\n",
    "\n",
    "import time\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "\n",
    "PATH_TO_SAVED_MODEL = PATH_TO_MODEL_DIR + \"/saved_model\"\n",
    "\n",
    "print('Loading model...', end='')\n",
    "start_time = time.time()\n",
    "\n",
    "# LOAD SAVED MODEL AND BUILD DETECTION FUNCTION\n",
    "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('Done! Took {} seconds'.format(elapsed_time))\n",
    "\n",
    "# LOAD LABEL MAP DATA FOR PLOTTING\n",
    "\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
    "                                                                    use_display_name=True)\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n",
    "\n",
    "def load_image_into_numpy_array(path):\n",
    "    \"\"\"Load an image from file into a numpy array.\n",
    "    Puts image into numpy array to feed into tensorflow graph.\n",
    "    Note that by convention we put it into a numpy array with shape\n",
    "    (height, width, channels), where channels=3 for RGB.\n",
    "    Args:\n",
    "      path: the file path to the image\n",
    "    Returns:\n",
    "      uint8 numpy array with shape (img_height, img_width, 3)\n",
    "    \"\"\"\n",
    "    return np.array(Image.open(path))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Running inference for {}... '.format(IMAGE_PATHS), end='')\n",
    "\n",
    "image = cv2.imread(IMAGE_PATHS)\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "image_expanded = np.expand_dims(image_rgb, axis=0)\n",
    "\n",
    "# The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "input_tensor = tf.convert_to_tensor(image)\n",
    "# The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "input_tensor = input_tensor[tf.newaxis, ...]\n",
    "\n",
    "# input_tensor = np.expand_dims(image_np, 0)\n",
    "detections = detect_fn(input_tensor)\n",
    "\n",
    "# All outputs are batches tensors.\n",
    "# Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "# We're only interested in the first num_detections.\n",
    "num_detections = int(detections.pop('num_detections'))\n",
    "detections = {key: value[0, :num_detections].numpy()\n",
    "               for key, value in detections.items()}\n",
    "detections['num_detections'] = num_detections\n",
    "\n",
    "# detection_classes should be ints.\n",
    "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "image_with_detections = image.copy()\n",
    "\n",
    "# SET MIN_SCORE_THRESH BASED ON YOU MINIMUM THRESHOLD FOR DETECTIONS\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "      image_with_detections,\n",
    "      detections['detection_boxes'],\n",
    "      detections['detection_classes'],\n",
    "      detections['detection_scores'],\n",
    "      category_index,\n",
    "      use_normalized_coordinates=True,\n",
    "      max_boxes_to_draw=200,\n",
    "      min_score_thresh=0.5,\n",
    "      agnostic_mode=False)\n",
    "\n",
    "print('Done')\n",
    "# DISPLAYS OUTPUT IMAGE\n",
    "#cv2.imshow('image', image_with_detections)\n",
    "im = image_with_detections\n",
    "cv2_imshow(image_with_detections)\n",
    "cv2.waitKey()  \n",
    "cv2.destroyAllWindows()\n",
    "# CLOSES WINDOW ONCE KEY IS PRESSED"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "Custom Object Detection.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
